{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from patsy import dmatrices\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set default figure size to be larger \n",
    "## this may only work in matplotlib 2.0+!\n",
    "matplotlib.rcParams['figure.figsize'] = [10.0,6.0]\n",
    "## Enable multiple outputs from jupyter cells\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.7 |Anaconda custom (64-bit)| (default, Oct 23 2018, 14:01:38) \n",
      "[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]\n",
      "Pandas version: 0.23.4\n",
      "Matplotlib version: 3.0.2\n",
      "Numpy version: 1.15.4\n",
      "SciKitLearn version: 0.20.1\n",
      "Dask version: 1.0.0\n"
     ]
    }
   ],
   "source": [
    "## Get Version information\n",
    "print(sys.version)\n",
    "print(\"Pandas version: {0}\".format(pd.__version__))\n",
    "print(\"Matplotlib version: {0}\".format(matplotlib.__version__))\n",
    "print(\"Numpy version: {0}\".format(np.__version__))\n",
    "print(\"SciKitLearn version: {0}\".format(sklearn.__version__))\n",
    "print(\"Dask version: {0}\".format(dask.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My working director:\n",
      "/Users/wenhuizeng/Library/Mobile Documents/com~apple~CloudDocs/high performance/week13\n",
      "My working director:\n",
      "/Users/wenhuizeng/Library/Mobile Documents/com~apple~CloudDocs/high performance/week12\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"My working director:\\n\" + os.getcwd())\n",
    "os.chdir(r\"/Users/wenhuizeng/Library/Mobile Documents/com~apple~CloudDocs/high performance/week12\")\n",
    "print(\"My working director:\\n\" + os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Myocardial_infarction</th>\n",
       "      <th>Congestive_heart_failure</th>\n",
       "      <th>Peripheral_vascular_disease</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Dementia</th>\n",
       "      <th>Pulmonary</th>\n",
       "      <th>...</th>\n",
       "      <th>Metastatic_solid_tumour</th>\n",
       "      <th>HIV</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>First_Appointment_Date</th>\n",
       "      <th>Last_Appointment_Date</th>\n",
       "      <th>DateOfDeath</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1962-02-27</td>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1959-08-18</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-11-30</td>\n",
       "      <td>2008-11-02</td>\n",
       "      <td>2008-11-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1946-02-15</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1979-07-27</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>2016-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1983-02-19</td>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-09-22</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID DateOfBirth  Gender      Race  Myocardial_infarction  \\\n",
       "0          1  1962-02-27  female  hispanic                      0   \n",
       "1          2  1959-08-18    male     white                      0   \n",
       "2          3  1946-02-15  female     white                      0   \n",
       "3          4  1979-07-27  female     white                      0   \n",
       "4          5  1983-02-19  female  hispanic                      0   \n",
       "\n",
       "   Congestive_heart_failure  Peripheral_vascular_disease  Stroke  Dementia  \\\n",
       "0                         0                            0       0         0   \n",
       "1                         0                            0       0         0   \n",
       "2                         0                            0       0         0   \n",
       "3                         0                            0       0         0   \n",
       "4                         0                            0       0         0   \n",
       "\n",
       "   Pulmonary     ...       Metastatic_solid_tumour  HIV  Obesity  Depression  \\\n",
       "0          0     ...                             0    0        0           0   \n",
       "1          0     ...                             0    0        0           0   \n",
       "2          0     ...                             0    1        0           0   \n",
       "3          1     ...                             0    0        0           0   \n",
       "4          0     ...                             0    0        0           0   \n",
       "\n",
       "   Hypertension  Drugs  Alcohol  First_Appointment_Date  \\\n",
       "0             0      0        0              2013-04-27   \n",
       "1             1      0        0              2005-11-30   \n",
       "2             1      0        0              2011-11-05   \n",
       "3             0      0        0              2010-03-01   \n",
       "4             1      0        0              2006-09-22   \n",
       "\n",
       "   Last_Appointment_Date  DateOfDeath  \n",
       "0             2018-06-01          NaN  \n",
       "1             2008-11-02   2008-11-02  \n",
       "2             2015-11-13          NaN  \n",
       "3             2016-01-17   2016-01-17  \n",
       "4             2018-06-01          NaN  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Index(['PatientID', 'DateOfBirth', 'Gender', 'Race', 'Myocardial_infarction',\n",
       "       'Congestive_heart_failure', 'Peripheral_vascular_disease', 'Stroke',\n",
       "       'Dementia', 'Pulmonary', 'Rheumatic', 'Peptic_ulcer_disease',\n",
       "       'LiverMild', 'Diabetes_without_complications',\n",
       "       'Diabetes_with_complications', 'Paralysis', 'Renal', 'Cancer',\n",
       "       'LiverSevere', 'Metastatic_solid_tumour', 'HIV', 'Obesity',\n",
       "       'Depression', 'Hypertension', 'Drugs', 'Alcohol',\n",
       "       'First_Appointment_Date', 'Last_Appointment_Date', 'DateOfDeath'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set print limits\n",
    "pd.options.display.max_rows = 10\n",
    "## Import Data\n",
    "df_patient = pd.read_csv('PatientAnalyticFile.csv')\n",
    "df_patient.head()\n",
    "df_patient.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20000.000000\n",
       "mean         0.354700\n",
       "std          0.478434\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          1.000000\n",
       "max          1.000000\n",
       "Name: death, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patient['death']=np.where(df_patient['DateOfDeath'].isnull(),0,1)\n",
    "df_patient['death'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>Myocardial_infarction</th>\n",
       "      <th>Congestive_heart_failure</th>\n",
       "      <th>Peripheral_vascular_disease</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Dementia</th>\n",
       "      <th>Pulmonary</th>\n",
       "      <th>Rheumatic</th>\n",
       "      <th>Peptic_ulcer_disease</th>\n",
       "      <th>LiverMild</th>\n",
       "      <th>...</th>\n",
       "      <th>Cancer</th>\n",
       "      <th>LiverSevere</th>\n",
       "      <th>Metastatic_solid_tumour</th>\n",
       "      <th>HIV</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.043450</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.028650</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>0.009250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.050450</td>\n",
       "      <td>0.051450</td>\n",
       "      <td>0.033150</td>\n",
       "      <td>0.006450</td>\n",
       "      <td>0.163450</td>\n",
       "      <td>0.106300</td>\n",
       "      <td>0.302900</td>\n",
       "      <td>0.040050</td>\n",
       "      <td>0.079750</td>\n",
       "      <td>0.354700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5773.647028</td>\n",
       "      <td>0.208621</td>\n",
       "      <td>0.203873</td>\n",
       "      <td>0.152897</td>\n",
       "      <td>0.166825</td>\n",
       "      <td>0.174401</td>\n",
       "      <td>0.259568</td>\n",
       "      <td>0.110224</td>\n",
       "      <td>0.097762</td>\n",
       "      <td>0.095733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.218877</td>\n",
       "      <td>0.220919</td>\n",
       "      <td>0.179033</td>\n",
       "      <td>0.080054</td>\n",
       "      <td>0.369785</td>\n",
       "      <td>0.308229</td>\n",
       "      <td>0.459524</td>\n",
       "      <td>0.196081</td>\n",
       "      <td>0.270913</td>\n",
       "      <td>0.478434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5000.750000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10000.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15000.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PatientID  Myocardial_infarction  Congestive_heart_failure  \\\n",
       "count  20000.000000           20000.000000              20000.000000   \n",
       "mean   10000.500000               0.045600                  0.043450   \n",
       "std     5773.647028               0.208621                  0.203873   \n",
       "min        1.000000               0.000000                  0.000000   \n",
       "25%     5000.750000               0.000000                  0.000000   \n",
       "50%    10000.500000               0.000000                  0.000000   \n",
       "75%    15000.250000               0.000000                  0.000000   \n",
       "max    20000.000000               1.000000                  1.000000   \n",
       "\n",
       "       Peripheral_vascular_disease        Stroke      Dementia     Pulmonary  \\\n",
       "count                 20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean                      0.023950      0.028650      0.031400      0.072650   \n",
       "std                       0.152897      0.166825      0.174401      0.259568   \n",
       "min                       0.000000      0.000000      0.000000      0.000000   \n",
       "25%                       0.000000      0.000000      0.000000      0.000000   \n",
       "50%                       0.000000      0.000000      0.000000      0.000000   \n",
       "75%                       0.000000      0.000000      0.000000      0.000000   \n",
       "max                       1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "          Rheumatic  Peptic_ulcer_disease     LiverMild      ...       \\\n",
       "count  20000.000000          20000.000000  20000.000000      ...        \n",
       "mean       0.012300              0.009650      0.009250      ...        \n",
       "std        0.110224              0.097762      0.095733      ...        \n",
       "min        0.000000              0.000000      0.000000      ...        \n",
       "25%        0.000000              0.000000      0.000000      ...        \n",
       "50%        0.000000              0.000000      0.000000      ...        \n",
       "75%        0.000000              0.000000      0.000000      ...        \n",
       "max        1.000000              1.000000      1.000000      ...        \n",
       "\n",
       "             Cancer   LiverSevere  Metastatic_solid_tumour           HIV  \\\n",
       "count  20000.000000  20000.000000             20000.000000  20000.000000   \n",
       "mean       0.050450      0.051450                 0.033150      0.006450   \n",
       "std        0.218877      0.220919                 0.179033      0.080054   \n",
       "min        0.000000      0.000000                 0.000000      0.000000   \n",
       "25%        0.000000      0.000000                 0.000000      0.000000   \n",
       "50%        0.000000      0.000000                 0.000000      0.000000   \n",
       "75%        0.000000      0.000000                 0.000000      0.000000   \n",
       "max        1.000000      1.000000                 1.000000      1.000000   \n",
       "\n",
       "            Obesity    Depression  Hypertension         Drugs       Alcohol  \\\n",
       "count  20000.000000  20000.000000  20000.000000  20000.000000  20000.000000   \n",
       "mean       0.163450      0.106300      0.302900      0.040050      0.079750   \n",
       "std        0.369785      0.308229      0.459524      0.196081      0.270913   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "              death  \n",
       "count  20000.000000  \n",
       "mean       0.354700  \n",
       "std        0.478434  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        1.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patient.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatientID                  int64\n",
       "DateOfBirth               object\n",
       "Gender                    object\n",
       "Race                      object\n",
       "Myocardial_infarction      int64\n",
       "                           ...  \n",
       "Alcohol                    int64\n",
       "First_Appointment_Date    object\n",
       "Last_Appointment_Date     object\n",
       "DateOfDeath               object\n",
       "death                      int64\n",
       "Length: 30, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patient.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    20000.000000\n",
       "mean        51.548638\n",
       "std         18.145086\n",
       "min         20.054757\n",
       "25%         36.034908\n",
       "50%         51.400411\n",
       "75%         67.225188\n",
       "max         83.044490\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_patient['DateOfBirth']=pd.to_datetime(df_patient['DateOfBirth'])\n",
    "df_patient['Age'] = ((pd.to_datetime('2019-04-21')-df_patient['DateOfBirth']).dt.days)/365.25\n",
    "df_patient['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'death ~ Dementia+Stroke+Obesity+Congestive_heart_failure+Diabetes_with_complications+death+Age+Race+LiverSevere+LiverMild+Hypertension+Peptic_ulcer_disease+Alcohol+Depression+Gender+Pulmonary+Myocardial_infarction+Cancer+Peripheral_vascular_disease+Drugs+Renal+Metastatic_solid_tumour+Rheumatic+Paralysis+HIV+Diabetes_without_complications'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars_remove = ['PatientID','First_Appointment_Date','DateOfBirth',\n",
    "               'Last_Appointment_Date','DateOfDeath','mortality']\n",
    "vars_left = set(df_patient.columns)-set(vars_remove)\n",
    "formula = 'death ~ ' + '+'.join(vars_left)\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_sub = df_patient.sample(frac=0.1,random_state=42)\n",
    "Y,X =dmatrices(formula,df_patient_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,np.ravel(Y),test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 29)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 29)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.62933333)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyClassifier(constant=None, random_state=0, strategy='most_frequent')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array(0.62933333)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "clf = DummyClassifier(strategy='most_frequent',random_state=0)\n",
    "clf.fit(x_train,y_train)\n",
    "clf.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores = {}\n",
    "def get_results(x1):\n",
    "    print(\"\\n{0:20}   {1:4}    {2:4}\".format('Model','Train','Test'))\n",
    "    print('-------------------------------------------')\n",
    "    for i in x1.keys():\n",
    "        print(\"{0:20}   {1:<6.4}   {2:<6.4}\".format(i,x1[i][0],x1[i][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Null                   0.6293   0.7   \n"
     ]
    }
   ],
   "source": [
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores['Null'] = (sklearn.metrics.accuracy_score(y_train,clf.predict(x_train)),\n",
    "                        sklearn.metrics.accuracy_score(y_test,clf.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with the SAG Solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will start with a logistic regression model, using the `solver=sag` option. \n",
    "* SAG handles an L2 penalty (not L1)\n",
    "* For any SAG based approach, the model optimization is sensitive to the scale of the inputs. So we must scale our parameters on the way in! \n",
    "* We can use the pipeline approach to preprocess the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logit', LogisticRegressionCV(Cs=20, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=False, intercept_scaling=1.0, max_iter=500,\n",
       "           multi_class='warn', n_jobs=None, penalty='l2', random_state=10,\n",
       "           refit=True, scoring=None, solver='sag', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "clf = linear_model.LogisticRegressionCV(solver='sag',fit_intercept=False,\n",
    "                                       Cs=20,cv=5,penalty='l2',\n",
    "                                       max_iter = 500,random_state=10)\n",
    "pipe1 = Pipeline([('scaler',scaler),\n",
    "                 ('logit',clf)])\n",
    "pipe1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores['logit_sag'] = (sklearn.metrics.accuracy_score(y_train,pipe1.predict(x_train)),\n",
    "                        sklearn.metrics.accuracy_score(y_test,pipe1.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with the SAGA Solver\n",
    "\n",
    "* We will start with a logistic regression model, using the `solver=saga` option. \n",
    "* SAGA handles an L1 penalty (not L2)\n",
    "* For any SAG based approach, the model optimization is sensitive to the scale of the inputs. So we must scale our parameters on the way in! \n",
    "* We can use the pipeline approach to preprocess the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('logit_saga', LogisticRegressionCV(Cs=20, class_weight=None, cv=5, dual=False,\n",
       "           fit_intercept=False, intercept_scaling=1.0, max_iter=500,\n",
       "           multi_class='warn', n_jobs=None, penalty='l1', random_state=10,\n",
       "           refit=True, scoring=None, solver='saga', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "clf = linear_model.LogisticRegressionCV(solver='saga',penalty='l1',\n",
    "                                       Cs=20,cv=5,fit_intercept=False,max_iter=500,random_state=10)\n",
    "\n",
    "pipe2 = Pipeline([('scaler',scaler),('logit_saga',clf)])\n",
    "\n",
    "pipe2.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_scores['logit_saga'] = (sklearn.metrics.accuracy_score(y_train,pipe2.predict(x_train)),\n",
    "                        sklearn.metrics.accuracy_score(y_test,pipe2.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent in Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 197.27, NNZs: 28, Bias: 0.000000, T: 1500, Avg. loss: 1.887628\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 139.25, NNZs: 28, Bias: 0.000000, T: 3000, Avg. loss: 0.133229\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 105.18, NNZs: 28, Bias: 0.000000, T: 4500, Avg. loss: 0.050321\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 85.42, NNZs: 28, Bias: 0.000000, T: 6000, Avg. loss: 0.006401\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 70.35, NNZs: 28, Bias: 0.000000, T: 7500, Avg. loss: 0.000007\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 59.80, NNZs: 28, Bias: 0.000000, T: 9000, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 52.00, NNZs: 28, Bias: 0.000000, T: 10500, Avg. loss: 0.000003\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 46.00, NNZs: 28, Bias: 0.000000, T: 12000, Avg. loss: 0.000002\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 41.24, NNZs: 28, Bias: 0.000000, T: 13500, Avg. loss: 0.000003\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 37.37, NNZs: 28, Bias: 0.000000, T: 15000, Avg. loss: 0.000005\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 34.17, NNZs: 28, Bias: 0.000000, T: 16500, Avg. loss: 0.000006\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 11 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sgd', SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=False,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=12, shuffle=True, tol=1e-06,\n",
       "       validation_fraction=0.1, verbose=1, warm_start=False))])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "clf =  linear_model.SGDClassifier(fit_intercept=False,\n",
    "                                 loss='log',\n",
    "                                 shuffle=True,\n",
    "                                 verbose=1,\n",
    "                                 random_state=12,\n",
    "                                 max_iter=1000,\n",
    "                                 tol=1e-6)\n",
    "pipe3 = Pipeline([('scale',scaler),\n",
    "                 ('sgd',clf)])\n",
    "\n",
    "pipe3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['SAG'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,pipe3.predict(x_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,pipe3.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.39, NNZs: 2, Bias: 0.000000, T: 1500, Avg. loss: 0.552883\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.39, NNZs: 2, Bias: 0.000000, T: 3000, Avg. loss: 0.555532\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.39, NNZs: 2, Bias: 0.000000, T: 4500, Avg. loss: 0.554717\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.39, NNZs: 2, Bias: 0.000000, T: 6000, Avg. loss: 0.554792\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.39, NNZs: 2, Bias: 0.000000, T: 7500, Avg. loss: 0.554900\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.39, NNZs: 2, Bias: 0.000000, T: 9000, Avg. loss: 0.554792\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 6 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sdg', SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=1000, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=12, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=False))])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "clf = linear_model.SGDClassifier(loss='log',fit_intercept=False,\n",
    "                                penalty='elasticnet',\n",
    "                                alpha=1,\n",
    "                                shuffle=True,\n",
    "                                verbose=1,\n",
    "                                random_state=12,\n",
    "                                max_iter=1000,\n",
    "                                tol=1e-6)\n",
    "\n",
    "pipe3 = Pipeline([('scaler',scaler),('sdg',clf)])\n",
    "\n",
    "pipe3.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['SAG_regularize'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,pipe3.predict(x_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,pipe3.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('sdg', GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=False,\n",
       "       l1_ra...     pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0))])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'alpha':(0.001,0.01,0.5,1,2,5,10),\n",
    "              'l1_ratio':(0,0.1,0.25,0.5,0.75,0.9,1)}\n",
    "\n",
    "clf = linear_model.SGDClassifier(fit_intercept=False,\n",
    "                                loss='log',\n",
    "                                penalty='elasticnet',\n",
    "                                shuffle=True,\n",
    "                                random_state=12,\n",
    "                                max_iter=1000,\n",
    "                                tol=1e-6)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "clf2 = GridSearchCV(clf,parameters,cv=5,return_train_score=True)\n",
    "\n",
    "pipe4 = Pipeline([('scale',scaler),\n",
    "                 ('sdg',clf2)])\n",
    "\n",
    "pipe4.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00513082, 0.00424204, 0.00477939, 0.00291638, 0.00259571,\n",
       "        0.0026855 , 0.00259175, 0.00255618, 0.00280328, 0.00474625,\n",
       "        0.00316377, 0.00419192, 0.00337014, 0.00315814, 0.00375938,\n",
       "        0.0034636 , 0.00371437, 0.00326142, 0.00410542, 0.00394044,\n",
       "        0.00235672, 0.0030848 , 0.00308018, 0.00304604, 0.00234785,\n",
       "        0.00253463, 0.0025125 , 0.00249758, 0.00346508, 0.00277653,\n",
       "        0.00232391, 0.0023458 , 0.00224085, 0.00230193, 0.00226235,\n",
       "        0.00327501, 0.00246577, 0.00350637, 0.00356431, 0.00357528,\n",
       "        0.0035048 , 0.00350819, 0.00469928, 0.0035708 , 0.00344481,\n",
       "        0.00349135, 0.00346861, 0.00335822, 0.01938376]),\n",
       " 'std_fit_time': array([3.60272844e-04, 6.75854001e-04, 1.19791106e-03, 2.60699150e-04,\n",
       "        1.42087664e-04, 1.46023966e-04, 2.27754798e-04, 8.84453366e-05,\n",
       "        1.14515936e-04, 2.44179762e-03, 3.32300607e-04, 5.46063754e-04,\n",
       "        6.49094178e-04, 5.81705557e-04, 3.13069650e-04, 5.95686930e-04,\n",
       "        6.14989962e-04, 5.92999579e-04, 1.92256654e-03, 1.98684352e-03,\n",
       "        1.06832000e-04, 4.50517014e-04, 6.83108472e-04, 6.35440790e-04,\n",
       "        1.08963770e-04, 3.12621220e-05, 1.33273589e-04, 1.29807879e-04,\n",
       "        1.15843248e-03, 5.35957173e-04, 8.46228652e-05, 1.47522197e-04,\n",
       "        4.98608440e-06, 6.15140264e-05, 2.44576096e-05, 1.30481378e-03,\n",
       "        1.43141908e-04, 1.72107171e-05, 1.31999292e-04, 1.85649210e-04,\n",
       "        1.38614881e-04, 9.98853321e-05, 2.03039306e-03, 1.50888110e-04,\n",
       "        4.04872657e-05, 2.62820772e-05, 8.63621207e-05, 1.71370697e-04,\n",
       "        3.21641135e-02]),\n",
       " 'mean_score_time': array([0.00260653, 0.00075798, 0.00067048, 0.00044923, 0.0002955 ,\n",
       "        0.00032649, 0.00030112, 0.00032482, 0.00029316, 0.00062451,\n",
       "        0.00057759, 0.00049615, 0.00044785, 0.0004652 , 0.00033054,\n",
       "        0.00029721, 0.00029721, 0.00034142, 0.00032344, 0.00033765,\n",
       "        0.00026579, 0.0002862 , 0.00027566, 0.00027843, 0.00026541,\n",
       "        0.00027137, 0.00026608, 0.000278  , 0.0002687 , 0.00027266,\n",
       "        0.00026903, 0.00027318, 0.00025678, 0.00026774, 0.00026922,\n",
       "        0.00028396, 0.00027547, 0.00977435, 0.00561881, 0.00044737,\n",
       "        0.0004468 , 0.00295   , 0.00847764, 0.00657582, 0.00423284,\n",
       "        0.0030282 , 0.00044737, 0.00060616, 0.00429597]),\n",
       " 'std_score_time': array([4.03290069e-03, 3.23939645e-04, 4.42579727e-04, 1.94594282e-04,\n",
       "        2.93983160e-05, 7.72257762e-05, 4.55463112e-05, 8.98710414e-05,\n",
       "        1.79449224e-05, 4.23932386e-04, 3.63998747e-04, 1.34062070e-04,\n",
       "        1.28684965e-04, 2.75146089e-04, 4.08178178e-05, 2.71397849e-05,\n",
       "        2.57061669e-05, 1.42086272e-05, 7.49824877e-05, 3.74240928e-05,\n",
       "        3.61390978e-06, 2.05928518e-05, 1.46408421e-05, 1.97311506e-05,\n",
       "        8.11380145e-06, 1.26908577e-05, 8.15795776e-06, 2.04801421e-05,\n",
       "        2.50509749e-06, 4.13668259e-06, 1.05505003e-05, 1.59105062e-05,\n",
       "        2.92391009e-06, 1.16966124e-05, 1.74468976e-05, 2.47271218e-05,\n",
       "        1.92151767e-05, 1.80052435e-03, 4.66797513e-03, 1.93666342e-05,\n",
       "        2.99812667e-05, 3.11226683e-03, 1.84966971e-03, 5.01901232e-03,\n",
       "        4.67826602e-03, 3.86341801e-03, 4.92415121e-05, 4.33155226e-04,\n",
       "        5.64379458e-03]),\n",
       " 'param_alpha': masked_array(data=[0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.5, 0.5, 0.5, 0.5,\n",
       "                    0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "                    2, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_l1_ratio': masked_array(data=[0, 0.1, 0.25, 0.5, 0.75, 0.9, 1, 0, 0.1, 0.25, 0.5,\n",
       "                    0.75, 0.9, 1, 0, 0.1, 0.25, 0.5, 0.75, 0.9, 1, 0, 0.1,\n",
       "                    0.25, 0.5, 0.75, 0.9, 1, 0, 0.1, 0.25, 0.5, 0.75, 0.9,\n",
       "                    1, 0, 0.1, 0.25, 0.5, 0.75, 0.9, 1, 0, 0.1, 0.25, 0.5,\n",
       "                    0.75, 0.9, 1],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'alpha': 0.001, 'l1_ratio': 0},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.25},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.75},\n",
       "  {'alpha': 0.001, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.001, 'l1_ratio': 1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.25},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.75},\n",
       "  {'alpha': 0.01, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.01, 'l1_ratio': 1},\n",
       "  {'alpha': 0.5, 'l1_ratio': 0},\n",
       "  {'alpha': 0.5, 'l1_ratio': 0.1},\n",
       "  {'alpha': 0.5, 'l1_ratio': 0.25},\n",
       "  {'alpha': 0.5, 'l1_ratio': 0.5},\n",
       "  {'alpha': 0.5, 'l1_ratio': 0.75},\n",
       "  {'alpha': 0.5, 'l1_ratio': 0.9},\n",
       "  {'alpha': 0.5, 'l1_ratio': 1},\n",
       "  {'alpha': 1, 'l1_ratio': 0},\n",
       "  {'alpha': 1, 'l1_ratio': 0.1},\n",
       "  {'alpha': 1, 'l1_ratio': 0.25},\n",
       "  {'alpha': 1, 'l1_ratio': 0.5},\n",
       "  {'alpha': 1, 'l1_ratio': 0.75},\n",
       "  {'alpha': 1, 'l1_ratio': 0.9},\n",
       "  {'alpha': 1, 'l1_ratio': 1},\n",
       "  {'alpha': 2, 'l1_ratio': 0},\n",
       "  {'alpha': 2, 'l1_ratio': 0.1},\n",
       "  {'alpha': 2, 'l1_ratio': 0.25},\n",
       "  {'alpha': 2, 'l1_ratio': 0.5},\n",
       "  {'alpha': 2, 'l1_ratio': 0.75},\n",
       "  {'alpha': 2, 'l1_ratio': 0.9},\n",
       "  {'alpha': 2, 'l1_ratio': 1},\n",
       "  {'alpha': 5, 'l1_ratio': 0},\n",
       "  {'alpha': 5, 'l1_ratio': 0.1},\n",
       "  {'alpha': 5, 'l1_ratio': 0.25},\n",
       "  {'alpha': 5, 'l1_ratio': 0.5},\n",
       "  {'alpha': 5, 'l1_ratio': 0.75},\n",
       "  {'alpha': 5, 'l1_ratio': 0.9},\n",
       "  {'alpha': 5, 'l1_ratio': 1},\n",
       "  {'alpha': 10, 'l1_ratio': 0},\n",
       "  {'alpha': 10, 'l1_ratio': 0.1},\n",
       "  {'alpha': 10, 'l1_ratio': 0.25},\n",
       "  {'alpha': 10, 'l1_ratio': 0.5},\n",
       "  {'alpha': 10, 'l1_ratio': 0.75},\n",
       "  {'alpha': 10, 'l1_ratio': 0.9},\n",
       "  {'alpha': 10, 'l1_ratio': 1}],\n",
       " 'split0_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62790698, 1.        , 1.        , 1.        , 0.62790698,\n",
       "        0.62790698, 0.62790698, 0.62790698, 0.99335548, 1.        ,\n",
       "        0.62790698, 0.62790698, 0.62790698, 0.62790698, 0.62790698,\n",
       "        0.99335548, 0.62790698, 0.62790698, 0.62790698, 0.62790698,\n",
       "        0.62790698, 0.62790698, 0.99003322, 0.62790698, 0.62790698,\n",
       "        0.62790698, 0.62790698, 0.62790698, 0.62790698]),\n",
       " 'split1_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.63      , 0.99666667, 1.        , 1.        , 0.63      ,\n",
       "        0.63      , 0.63      , 0.63      , 0.99666667, 1.        ,\n",
       "        0.63      , 0.63      , 0.63      , 0.63      , 0.63      ,\n",
       "        0.99666667, 0.63      , 0.63      , 0.63      , 0.63      ,\n",
       "        0.63      , 0.63      , 0.99666667, 0.63      , 0.63      ,\n",
       "        0.63      , 0.63      , 0.63      , 0.63      ]),\n",
       " 'split2_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.63      , 1.        , 1.        , 1.        , 0.63      ,\n",
       "        0.63      , 0.63      , 0.63      , 1.        , 1.        ,\n",
       "        0.63      , 0.63      , 0.63      , 0.63      , 0.63      ,\n",
       "        0.99666667, 0.63      , 0.63      , 0.63      , 0.63      ,\n",
       "        0.63      , 0.63      , 0.99666667, 0.63      , 0.63      ,\n",
       "        0.63      , 0.63      , 0.63      , 0.63      ]),\n",
       " 'split3_test_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99666667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.63      , 0.99333333, 1.        , 1.        , 0.63      ,\n",
       "        0.63      , 0.63      , 0.63      , 0.99333333, 1.        ,\n",
       "        0.63      , 0.63      , 0.63      , 0.63      , 0.63      ,\n",
       "        0.98666667, 0.63      , 0.63      , 0.63      , 0.63      ,\n",
       "        0.63      , 0.63      , 0.98666667, 0.63      , 0.63      ,\n",
       "        0.63      , 0.63      , 0.63      , 0.63      ]),\n",
       " 'split4_test_score': array([1.        , 0.99331104, 0.99331104, 0.99331104, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62876254, 0.99665552, 1.        , 1.        , 0.62876254,\n",
       "        0.62876254, 0.62876254, 0.62876254, 0.99331104, 1.        ,\n",
       "        0.62876254, 0.62876254, 0.62876254, 0.62876254, 0.62876254,\n",
       "        0.99331104, 0.62876254, 0.62876254, 0.62876254, 0.62876254,\n",
       "        0.62876254, 0.62876254, 0.99331104, 0.62876254, 0.62876254,\n",
       "        0.62876254, 0.62876254, 0.62876254, 0.62876254]),\n",
       " 'mean_test_score': array([1.        , 0.99866667, 0.99866667, 0.99866667, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99866667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62933333, 0.99733333, 1.        , 1.        , 0.62933333,\n",
       "        0.62933333, 0.62933333, 0.62933333, 0.99533333, 1.        ,\n",
       "        0.62933333, 0.62933333, 0.62933333, 0.62933333, 0.62933333,\n",
       "        0.99333333, 0.62933333, 0.62933333, 0.62933333, 0.62933333,\n",
       "        0.62933333, 0.62933333, 0.99266667, 0.62933333, 0.62933333,\n",
       "        0.62933333, 0.62933333, 0.62933333, 0.62933333]),\n",
       " 'std_test_score': array([0.        , 0.00267223, 0.00267223, 0.00267223, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00163299,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00086015, 0.00249593, 0.        , 0.        , 0.00086015,\n",
       "        0.00086015, 0.00086015, 0.00086015, 0.0026667 , 0.        ,\n",
       "        0.00086015, 0.00086015, 0.00086015, 0.00086015, 0.00086015,\n",
       "        0.00365151, 0.00086015, 0.00086015, 0.00086015, 0.00086015,\n",
       "        0.00086015, 0.00086015, 0.00388258, 0.00086015, 0.00086015,\n",
       "        0.00086015, 0.00086015, 0.00086015, 0.00086015]),\n",
       " 'rank_test_score': array([ 1, 20, 20, 20,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1, 20,  1,  1,\n",
       "         1,  1,  1, 28, 24,  1,  1, 28, 28, 28, 28, 25,  1, 28, 28, 28, 28,\n",
       "        28, 26, 28, 28, 28, 28, 28, 28, 27, 28, 28, 28, 28, 28, 28],\n",
       "       dtype=int32),\n",
       " 'split0_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99833194,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62969141, 0.99749791, 1.        , 1.        , 0.62969141,\n",
       "        0.62969141, 0.62969141, 0.62969141, 0.99582986, 1.        ,\n",
       "        0.62969141, 0.62969141, 0.62969141, 0.62969141, 0.62969141,\n",
       "        0.99499583, 0.62969141, 0.62969141, 0.62969141, 0.62969141,\n",
       "        0.62969141, 0.62969141, 0.99499583, 0.62969141, 0.62969141,\n",
       "        0.62969141, 0.62969141, 0.62969141, 0.62969141]),\n",
       " 'split1_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99916667,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62916667, 0.99666667, 1.        , 1.        , 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.99583333, 1.        ,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.62916667, 0.62916667,\n",
       "        0.99583333, 0.62916667, 0.62916667, 0.62916667, 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.995     , 0.62916667, 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.62916667]),\n",
       " 'split2_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.9975    ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62916667, 0.99666667, 1.        , 1.        , 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.99666667, 1.        ,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.62916667, 0.62916667,\n",
       "        0.99666667, 0.62916667, 0.62916667, 0.62916667, 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.99583333, 0.62916667, 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.62916667]),\n",
       " 'split3_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62916667, 0.99916667, 1.        , 1.        , 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.99583333, 1.        ,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.62916667, 0.62916667,\n",
       "        0.99583333, 0.62916667, 0.62916667, 0.62916667, 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.995     , 0.62916667, 0.62916667,\n",
       "        0.62916667, 0.62916667, 0.62916667, 0.62916667]),\n",
       " 'split4_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99916736,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62947544, 0.99833472, 1.        , 1.        , 0.62947544,\n",
       "        0.62947544, 0.62947544, 0.62947544, 0.99500416, 1.        ,\n",
       "        0.62947544, 0.62947544, 0.62947544, 0.62947544, 0.62947544,\n",
       "        0.99500416, 0.62947544, 0.62947544, 0.62947544, 0.62947544,\n",
       "        0.62947544, 0.62947544, 0.99417152, 0.62947544, 0.62947544,\n",
       "        0.62947544, 0.62947544, 0.62947544, 0.62947544]),\n",
       " 'mean_train_score': array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.99883319,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.62933337, 0.99766653, 1.        , 1.        , 0.62933337,\n",
       "        0.62933337, 0.62933337, 0.62933337, 0.99583347, 1.        ,\n",
       "        0.62933337, 0.62933337, 0.62933337, 0.62933337, 0.62933337,\n",
       "        0.99566667, 0.62933337, 0.62933337, 0.62933337, 0.62933337,\n",
       "        0.62933337, 0.62933337, 0.99500014, 0.62933337, 0.62933337,\n",
       "        0.62933337, 0.62933337, 0.62933337, 0.62933337]),\n",
       " 'std_train_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.00085005,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00021529, 0.00097209, 0.        , 0.        , 0.00021529,\n",
       "        0.00021529, 0.00021529, 0.00021529, 0.00052573, 0.        ,\n",
       "        0.00021529, 0.00021529, 0.00021529, 0.00021529, 0.00021529,\n",
       "        0.00062362, 0.00021529, 0.00021529, 0.00021529, 0.00021529,\n",
       "        0.00021529, 0.00021529, 0.00052552, 0.00021529, 0.00021529,\n",
       "        0.00021529, 0.00021529, 0.00021529, 0.00021529])}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check best model params\n",
    "pipe4.named_steps['sdg'].cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'l1_ratio': 0}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe4.named_steps['sdg'].best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Score the Model on Training and Testing Set\n",
    "result_scores['SAG_en_cv'] = \\\n",
    "            (sklearn.metrics.accuracy_score(y_train,pipe4.predict(x_train)),\n",
    "             sklearn.metrics.accuracy_score(y_test,pipe4.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model                  Train    Test\n",
      "-------------------------------------------\n",
      "Null                   0.6293   0.7   \n",
      "logit_sag              1.0      0.998 \n",
      "logit_saga             1.0      1.0   \n",
      "SAG                    1.0      1.0   \n",
      "SAG_regularize         1.0      1.0   \n",
      "SAG_en_cv              1.0      1.0   \n"
     ]
    }
   ],
   "source": [
    "get_results(result_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "     PatientID DateOfBirth  Gender      Race  Myocardial_infarction  \\\n",
      "0            1  1962-02-27  female  hispanic                      0   \n",
      "1            2  1959-08-18    male     white                      0   \n",
      "2            3  1946-02-15  female     white                      0   \n",
      "3            4  1979-07-27  female     white                      0   \n",
      "4            5  1983-02-19  female  hispanic                      0   \n",
      "..         ...         ...     ...       ...                    ...   \n",
      "995        996  1964-07-28  female     black                      0   \n",
      "996        997  1980-10-07    male     white                      0   \n",
      "997        998  1949-09-06    male     black                      0   \n",
      "998        999  1945-07-20    male     white                      0   \n",
      "999       1000  1987-04-14    male     white                      0   \n",
      "\n",
      "     Congestive_heart_failure  Peripheral_vascular_disease  Stroke  Dementia  \\\n",
      "0                           0                            0       0         0   \n",
      "1                           0                            0       0         0   \n",
      "2                           0                            0       0         0   \n",
      "3                           0                            0       0         0   \n",
      "4                           0                            0       0         0   \n",
      "..                        ...                          ...     ...       ...   \n",
      "995                         0                            0       0         0   \n",
      "996                         0                            0       0         0   \n",
      "997                         0                            0       0         0   \n",
      "998                         0                            0       0         0   \n",
      "999                         0                            0       0         0   \n",
      "\n",
      "     Pulmonary     ...       Metastatic_solid_tumour  HIV  Obesity  \\\n",
      "0            0     ...                             0    0        0   \n",
      "1            0     ...                             0    0        0   \n",
      "2            0     ...                             0    1        0   \n",
      "3            1     ...                             0    0        0   \n",
      "4            0     ...                             0    0        0   \n",
      "..         ...     ...                           ...  ...      ...   \n",
      "995          0     ...                             0    0        0   \n",
      "996          0     ...                             0    0        0   \n",
      "997          0     ...                             0    0        0   \n",
      "998          0     ...                             0    0        0   \n",
      "999          0     ...                             0    0        0   \n",
      "\n",
      "     Depression  Hypertension  Drugs  Alcohol  First_Appointment_Date  \\\n",
      "0             0             0      0        0              2013-04-27   \n",
      "1             0             1      0        0              2005-11-30   \n",
      "2             0             1      0        0              2011-11-05   \n",
      "3             0             0      0        0              2010-03-01   \n",
      "4             0             1      0        0              2006-09-22   \n",
      "..          ...           ...    ...      ...                     ...   \n",
      "995           0             0      0        0              2013-10-22   \n",
      "996           0             1      0        0              2008-09-14   \n",
      "997           0             1      0        0              2006-08-22   \n",
      "998           0             1      0        0              2005-06-10   \n",
      "999           0             1      0        0              2006-04-11   \n",
      "\n",
      "     Last_Appointment_Date  DateOfDeath  \n",
      "0               2018-06-01          NaN  \n",
      "1               2008-11-02   2008-11-02  \n",
      "2               2015-11-13          NaN  \n",
      "3               2016-01-17   2016-01-17  \n",
      "4               2018-06-01          NaN  \n",
      "..                     ...          ...  \n",
      "995             2014-09-03          NaN  \n",
      "996             2018-06-01          NaN  \n",
      "997             2008-07-13   2008-07-13  \n",
      "998             2012-03-02   2012-03-02  \n",
      "999             2008-05-24   2008-05-24  \n",
      "\n",
      "[1000 rows x 29 columns]\n",
      "1\n",
      "      PatientID DateOfBirth  Gender      Race  Myocardial_infarction  \\\n",
      "1000       1001  1965-05-14    male     white                      0   \n",
      "1001       1002  1946-10-13    male  hispanic                      0   \n",
      "1002       1003  1975-07-27  female  hispanic                      0   \n",
      "1003       1004  1962-11-14    male     white                      0   \n",
      "1004       1005  1968-03-08    male     white                      0   \n",
      "...         ...         ...     ...       ...                    ...   \n",
      "1995       1996  1958-04-15  female     white                      0   \n",
      "1996       1997  1991-07-03    male     black                      0   \n",
      "1997       1998  1982-05-29  female     white                      0   \n",
      "1998       1999  1993-03-19  female  hispanic                      0   \n",
      "1999       2000  1951-05-31    male     black                      0   \n",
      "\n",
      "      Congestive_heart_failure  Peripheral_vascular_disease  Stroke  Dementia  \\\n",
      "1000                         0                            0       0         0   \n",
      "1001                         0                            0       0         0   \n",
      "1002                         0                            0       0         0   \n",
      "1003                         0                            0       0         0   \n",
      "1004                         0                            0       0         1   \n",
      "...                        ...                          ...     ...       ...   \n",
      "1995                         0                            0       0         0   \n",
      "1996                         0                            0       0         0   \n",
      "1997                         0                            0       0         0   \n",
      "1998                         0                            0       0         0   \n",
      "1999                         0                            0       0         0   \n",
      "\n",
      "      Pulmonary     ...       Metastatic_solid_tumour  HIV  Obesity  \\\n",
      "1000          0     ...                             0    0        0   \n",
      "1001          0     ...                             0    0        1   \n",
      "1002          0     ...                             0    0        0   \n",
      "1003          0     ...                             0    0        0   \n",
      "1004          0     ...                             0    0        1   \n",
      "...         ...     ...                           ...  ...      ...   \n",
      "1995          0     ...                             0    0        0   \n",
      "1996          0     ...                             0    0        0   \n",
      "1997          0     ...                             0    0        0   \n",
      "1998          0     ...                             0    0        0   \n",
      "1999          0     ...                             0    0        0   \n",
      "\n",
      "      Depression  Hypertension  Drugs  Alcohol  First_Appointment_Date  \\\n",
      "1000           0             1      0        0              2007-07-23   \n",
      "1001           0             0      0        0              2006-09-12   \n",
      "1002           0             1      0        0              2009-02-26   \n",
      "1003           0             1      0        0              2009-09-15   \n",
      "1004           0             1      0        0              2012-02-12   \n",
      "...          ...           ...    ...      ...                     ...   \n",
      "1995           0             1      0        1              2015-04-24   \n",
      "1996           0             0      0        0              2014-05-08   \n",
      "1997           0             0      0        0              2014-03-22   \n",
      "1998           0             1      0        0              2012-05-20   \n",
      "1999           1             0      0        0              2006-07-15   \n",
      "\n",
      "      Last_Appointment_Date  DateOfDeath  \n",
      "1000             2018-06-01          NaN  \n",
      "1001             2008-12-30   2008-12-30  \n",
      "1002             2018-06-01          NaN  \n",
      "1003             2018-06-01          NaN  \n",
      "1004             2018-06-01          NaN  \n",
      "...                     ...          ...  \n",
      "1995             2018-06-01          NaN  \n",
      "1996             2018-06-01          NaN  \n",
      "1997             2018-06-01          NaN  \n",
      "1998             2018-06-01          NaN  \n",
      "1999             2007-10-17   2007-10-17  \n",
      "\n",
      "[1000 rows x 29 columns]\n",
      "2\n",
      "      PatientID DateOfBirth  Gender      Race  Myocardial_infarction  \\\n",
      "2000       2001  1941-06-19  female     white                      0   \n",
      "2001       2002  1950-04-01  female     white                      0   \n",
      "2002       2003  1955-01-17    male     white                      0   \n",
      "2003       2004  1966-09-08    male     black                      0   \n",
      "2004       2005  1975-11-28  female     black                      0   \n",
      "...         ...         ...     ...       ...                    ...   \n",
      "2995       2996  1984-01-01    male     black                      0   \n",
      "2996       2997  1949-09-16  female  hispanic                      0   \n",
      "2997       2998  1948-11-17  female     other                      0   \n",
      "2998       2999  1992-05-07  female  hispanic                      0   \n",
      "2999       3000  1961-11-01  female  hispanic                      0   \n",
      "\n",
      "      Congestive_heart_failure  Peripheral_vascular_disease  Stroke  Dementia  \\\n",
      "2000                         0                            0       0         0   \n",
      "2001                         0                            0       0         0   \n",
      "2002                         0                            0       0         0   \n",
      "2003                         0                            0       0         0   \n",
      "2004                         0                            0       0         0   \n",
      "...                        ...                          ...     ...       ...   \n",
      "2995                         0                            0       0         0   \n",
      "2996                         0                            0       0         0   \n",
      "2997                         0                            0       0         0   \n",
      "2998                         0                            0       0         0   \n",
      "2999                         0                            0       0         0   \n",
      "\n",
      "      Pulmonary     ...       Metastatic_solid_tumour  HIV  Obesity  \\\n",
      "2000          0     ...                             0    0        0   \n",
      "2001          0     ...                             0    0        0   \n",
      "2002          0     ...                             1    0        1   \n",
      "2003          0     ...                             0    0        0   \n",
      "2004          0     ...                             0    0        0   \n",
      "...         ...     ...                           ...  ...      ...   \n",
      "2995          0     ...                             0    0        1   \n",
      "2996          0     ...                             0    0        0   \n",
      "2997          0     ...                             0    0        0   \n",
      "2998          0     ...                             0    0        1   \n",
      "2999          1     ...                             0    0        0   \n",
      "\n",
      "      Depression  Hypertension  Drugs  Alcohol  First_Appointment_Date  \\\n",
      "2000           0             0      0        0              2007-05-22   \n",
      "2001           0             0      0        1              2009-03-15   \n",
      "2002           0             0      1        0              2014-09-20   \n",
      "2003           0             0      0        1              2013-01-16   \n",
      "2004           0             0      0        1              2011-07-31   \n",
      "...          ...           ...    ...      ...                     ...   \n",
      "2995           0             0      0        0              2014-07-06   \n",
      "2996           0             0      1        0              2007-02-03   \n",
      "2997           0             0      0        0              2006-11-27   \n",
      "2998           0             1      0        0              2008-10-28   \n",
      "2999           0             0      0        0              2006-08-29   \n",
      "\n",
      "      Last_Appointment_Date  DateOfDeath  \n",
      "2000             2007-12-06   2007-12-06  \n",
      "2001             2018-06-01          NaN  \n",
      "2002             2018-06-01          NaN  \n",
      "2003             2014-06-03   2014-06-03  \n",
      "2004             2018-06-01          NaN  \n",
      "...                     ...          ...  \n",
      "2995             2016-07-09          NaN  \n",
      "2996             2007-12-11   2007-12-11  \n",
      "2997             2007-12-15   2007-12-15  \n",
      "2998             2016-05-09          NaN  \n",
      "2999             2012-03-27          NaN  \n",
      "\n",
      "[1000 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df_patient_gen = pd.read_csv(r'PatientAnalyticFile.csv',chunksize=1000)\n",
    "for n,chunk in enumerate(df_patient_gen):\n",
    "    print(n)\n",
    "    print(chunk)\n",
    "    if n>1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Myocardial_infarction</th>\n",
       "      <th>Congestive_heart_failure</th>\n",
       "      <th>Peripheral_vascular_disease</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Dementia</th>\n",
       "      <th>Pulmonary</th>\n",
       "      <th>...</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>First_Appointment_Date</th>\n",
       "      <th>Last_Appointment_Date</th>\n",
       "      <th>DateOfDeath</th>\n",
       "      <th>mortality</th>\n",
       "      <th>Age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1962-02-27</td>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>57.144422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1959-08-18</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-11-30</td>\n",
       "      <td>2008-11-02</td>\n",
       "      <td>2008-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>59.674196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1946-02-15</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>73.177276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1979-07-27</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>1</td>\n",
       "      <td>39.734428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1983-02-19</td>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-09-22</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>36.167009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1987-11-16</td>\n",
       "      <td>male</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-10-22</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31.427789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1958-01-11</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>61.273101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1952-10-31</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>66.469541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1951-10-06</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-04</td>\n",
       "      <td>2010-05-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>67.540041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1954-10-16</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>64.511978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID DateOfBirth  Gender      Race  Myocardial_infarction  \\\n",
       "0          1  1962-02-27  female  hispanic                      0   \n",
       "1          2  1959-08-18    male     white                      0   \n",
       "2          3  1946-02-15  female     white                      0   \n",
       "3          4  1979-07-27  female     white                      0   \n",
       "4          5  1983-02-19  female  hispanic                      0   \n",
       "5          6  1987-11-16    male     black                      0   \n",
       "6          7  1958-01-11    male     white                      0   \n",
       "7          8  1952-10-31  female     black                      0   \n",
       "8          9  1951-10-06  female     white                      0   \n",
       "9         10  1954-10-16    male     white                      0   \n",
       "\n",
       "   Congestive_heart_failure  Peripheral_vascular_disease  Stroke  Dementia  \\\n",
       "0                         0                            0       0         0   \n",
       "1                         0                            0       0         0   \n",
       "2                         0                            0       0         0   \n",
       "3                         0                            0       0         0   \n",
       "4                         0                            0       0         0   \n",
       "5                         0                            0       0         0   \n",
       "6                         0                            0       0         0   \n",
       "7                         0                            0       0         0   \n",
       "8                         0                            0       0         0   \n",
       "9                         0                            0       0         0   \n",
       "\n",
       "   Pulmonary    ...      Obesity  Depression  Hypertension  Drugs  Alcohol  \\\n",
       "0          0    ...            0           0             0      0        0   \n",
       "1          0    ...            0           0             1      0        0   \n",
       "2          0    ...            0           0             1      0        0   \n",
       "3          1    ...            0           0             0      0        0   \n",
       "4          0    ...            0           0             1      0        0   \n",
       "5          0    ...            0           0             0      0        0   \n",
       "6          0    ...            0           0             0      0        0   \n",
       "7          0    ...            0           0             1      0        0   \n",
       "8          0    ...            0           1             0      0        0   \n",
       "9          0    ...            0           0             0      0        0   \n",
       "\n",
       "   First_Appointment_Date  Last_Appointment_Date  DateOfDeath  mortality  \\\n",
       "0              2013-04-27             2018-06-01          NaN          0   \n",
       "1              2005-11-30             2008-11-02   2008-11-02          1   \n",
       "2              2011-11-05             2015-11-13          NaN          0   \n",
       "3              2010-03-01             2016-01-17   2016-01-17          1   \n",
       "4              2006-09-22             2018-06-01          NaN          0   \n",
       "5              2006-10-22             2011-01-13          NaN          0   \n",
       "6              2015-01-20             2018-06-01          NaN          0   \n",
       "7              2013-03-25             2018-06-01          NaN          0   \n",
       "8              2008-08-04             2010-05-23          NaN          0   \n",
       "9              2014-07-01             2015-10-19          NaN          0   \n",
       "\n",
       "   Age_years  \n",
       "0  57.144422  \n",
       "1  59.674196  \n",
       "2  73.177276  \n",
       "3  39.734428  \n",
       "4  36.167009  \n",
       "5  31.427789  \n",
       "6  61.273101  \n",
       "7  66.469541  \n",
       "8  67.540041  \n",
       "9  64.511978  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(r'PatientAnalyticFile.csv',nrows=10)\n",
    "df1['mortality'] =  np.where(df1['DateOfDeath'].isnull(),0,1)\n",
    "df1['DateOfBirth'] = pd.to_datetime(df1['DateOfBirth'])\n",
    "df1['Age_years'] = ((pd.to_datetime('2019-04-21')-df1['DateOfBirth']).dt.days/365.25)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_years    32952.036793\n",
       "dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Age_years    557.119781\n",
       "dtype: float64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## standard numeric columns\n",
    "\n",
    "num_cols = ['Age_years']\n",
    "\n",
    "## categorical columns\n",
    "\n",
    "cat_cols = ['Gender', 'Race', 'Myocardial_infarction',\n",
    "       'Congestive_heart_failure', 'Peripheral_vascular_disease', 'Stroke',\n",
    "       'Dementia', 'Pulmonary', 'Rheumatic', 'Peptic_ulcer_disease',\n",
    "       'LiverMild', 'Diabetes_without_complications',\n",
    "       'Diabetes_with_complications', 'Paralysis', 'Renal', 'Cancer',\n",
    "       'LiverSevere', 'Metastatic_solid_tumour', 'HIV', 'Obesity',\n",
    "       'Depression', 'Hypertension', 'Drugs', 'Alcohol','mortality']\n",
    "\n",
    "def sum2(x):\n",
    "    return(np.sum(x**2))\n",
    "df1.loc[:,num_cols].agg(sum2,axis=0)\n",
    "df1.loc[:,num_cols].agg(np.sum,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Gender': {'female', 'male'},\n",
       " 'Race': {'black', 'hispanic', 'white'},\n",
       " 'Myocardial_infarction': {0},\n",
       " 'Congestive_heart_failure': {0},\n",
       " 'Peripheral_vascular_disease': {0},\n",
       " 'Stroke': {0},\n",
       " 'Dementia': {0},\n",
       " 'Pulmonary': {0, 1},\n",
       " 'Rheumatic': {0},\n",
       " 'Peptic_ulcer_disease': {0, 1},\n",
       " 'LiverMild': {0},\n",
       " 'Diabetes_without_complications': {0, 1},\n",
       " 'Diabetes_with_complications': {0},\n",
       " 'Paralysis': {0},\n",
       " 'Renal': {0},\n",
       " 'Cancer': {0, 1},\n",
       " 'LiverSevere': {0, 1},\n",
       " 'Metastatic_solid_tumour': {0},\n",
       " 'HIV': {0, 1},\n",
       " 'Obesity': {0},\n",
       " 'Depression': {0, 1},\n",
       " 'Hypertension': {0, 1},\n",
       " 'Drugs': {0},\n",
       " 'Alcohol': {0},\n",
       " 'mortality': {0, 1}}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'female', 'male'}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_unique = {}\n",
    "for col in cat_cols:\n",
    "    dict_unique[col] = set(df1.loc[:,col])\n",
    "dict_unique\n",
    "dict_unique['Gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_gen2 = pd.read_csv(r'PatientAnalyticFile.csv',chunksize=100)\n",
    "for n, chunk in enumerate(df_patient_gen2):\n",
    "    chunk['mortality']=np.where(chunk['DateOfDeath'].isnull(),0,1)\n",
    "    chunk['DateOfBirth'] = pd.to_datetime(chunk['DateOfBirth'])\n",
    "    chunk['Age_years'] =  ((pd.to_datetime('2019-04-22')-chunk['DateOfBirth']).dt.days/365.25)\n",
    "    if n==0:\n",
    "        n_rows=chunk.shape[0]\n",
    "        running_sum=chunk.loc[:,num_cols].agg(np.sum,axis=0)\n",
    "        running_sum_2 =  chunk.loc[:,num_cols].agg(sum2,axis=0)\n",
    "        dict_unique={}\n",
    "        for col in cat_cols:\n",
    "            dict_unique[col] = set(chunk.loc[:,col])\n",
    "    if n>0:\n",
    "        n_rows+=chunk.shape[0]\n",
    "        running_sum =  running_sum+chunk.loc[:,num_cols].agg(np.sum,axis=0)\n",
    "        running_sum_2 +=chunk.loc[:,num_cols].agg(sum2,axis=0)\n",
    "        for col in cat_cols:\n",
    "            dict_unique[col]=set(chunk.loc[:,col]).union(set(dict_unique[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age_years']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Age_years    1.031028e+06\n",
       "dtype: float64"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols\n",
    "n_rows\n",
    "running_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_years    51.551375\n",
       "dtype: float64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Age_years    18.144632\n",
       "dtype: float64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_all = running_sum/n_rows\n",
    "stdev_all = np.sqrt((running_sum_2/n_rows)-mean_all*mean_all)\n",
    "mean_all\n",
    "stdev_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age_years    47.247474\n",
       "dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Age_years    18.144632\n",
       "dtype: float64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## calculate mean\n",
    "mean_all = running_sum / n_rows\n",
    "## calculate stdev\n",
    "stdev_all = np.sqrt((running_sum_2 / n_rows) - (mean_all * mean_all)) \n",
    "## final nums to use for standardization:\n",
    "mean_all\n",
    "stdev_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PatientID</th>\n",
       "      <th>DateOfBirth</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Myocardial_infarction</th>\n",
       "      <th>Congestive_heart_failure</th>\n",
       "      <th>Peripheral_vascular_disease</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>Dementia</th>\n",
       "      <th>Pulmonary</th>\n",
       "      <th>...</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Drugs</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>First_Appointment_Date</th>\n",
       "      <th>Last_Appointment_Date</th>\n",
       "      <th>DateOfDeath</th>\n",
       "      <th>mortality</th>\n",
       "      <th>Age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1962-02-27</td>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-04-27</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>52.843258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1959-08-18</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2005-11-30</td>\n",
       "      <td>2008-11-02</td>\n",
       "      <td>2008-11-02</td>\n",
       "      <td>1</td>\n",
       "      <td>55.373032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1946-02-15</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2011-11-05</td>\n",
       "      <td>2015-11-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>68.876112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1979-07-27</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2010-03-01</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>2016-01-17</td>\n",
       "      <td>1</td>\n",
       "      <td>35.433265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1983-02-19</td>\n",
       "      <td>female</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-09-22</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31.865845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1987-11-16</td>\n",
       "      <td>male</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2006-10-22</td>\n",
       "      <td>2011-01-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>27.126626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1958-01-11</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>56.971937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1952-10-31</td>\n",
       "      <td>female</td>\n",
       "      <td>black</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-03-25</td>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>62.168378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1951-10-06</td>\n",
       "      <td>female</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2008-08-04</td>\n",
       "      <td>2010-05-23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>63.238877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1954-10-16</td>\n",
       "      <td>male</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>2015-10-19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>60.210815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PatientID DateOfBirth  Gender      Race  Myocardial_infarction  \\\n",
       "0          1  1962-02-27  female  hispanic                      0   \n",
       "1          2  1959-08-18    male     white                      0   \n",
       "2          3  1946-02-15  female     white                      0   \n",
       "3          4  1979-07-27  female     white                      0   \n",
       "4          5  1983-02-19  female  hispanic                      0   \n",
       "5          6  1987-11-16    male     black                      0   \n",
       "6          7  1958-01-11    male     white                      0   \n",
       "7          8  1952-10-31  female     black                      0   \n",
       "8          9  1951-10-06  female     white                      0   \n",
       "9         10  1954-10-16    male     white                      0   \n",
       "\n",
       "   Congestive_heart_failure  Peripheral_vascular_disease  Stroke  Dementia  \\\n",
       "0                         0                            0       0         0   \n",
       "1                         0                            0       0         0   \n",
       "2                         0                            0       0         0   \n",
       "3                         0                            0       0         0   \n",
       "4                         0                            0       0         0   \n",
       "5                         0                            0       0         0   \n",
       "6                         0                            0       0         0   \n",
       "7                         0                            0       0         0   \n",
       "8                         0                            0       0         0   \n",
       "9                         0                            0       0         0   \n",
       "\n",
       "   Pulmonary    ...      Obesity  Depression  Hypertension  Drugs  Alcohol  \\\n",
       "0          0    ...            0           0             0      0        0   \n",
       "1          0    ...            0           0             1      0        0   \n",
       "2          0    ...            0           0             1      0        0   \n",
       "3          1    ...            0           0             0      0        0   \n",
       "4          0    ...            0           0             1      0        0   \n",
       "5          0    ...            0           0             0      0        0   \n",
       "6          0    ...            0           0             0      0        0   \n",
       "7          0    ...            0           0             1      0        0   \n",
       "8          0    ...            0           1             0      0        0   \n",
       "9          0    ...            0           0             0      0        0   \n",
       "\n",
       "   First_Appointment_Date  Last_Appointment_Date  DateOfDeath  mortality  \\\n",
       "0              2013-04-27             2018-06-01          NaN          0   \n",
       "1              2005-11-30             2008-11-02   2008-11-02          1   \n",
       "2              2011-11-05             2015-11-13          NaN          0   \n",
       "3              2010-03-01             2016-01-17   2016-01-17          1   \n",
       "4              2006-09-22             2018-06-01          NaN          0   \n",
       "5              2006-10-22             2011-01-13          NaN          0   \n",
       "6              2015-01-20             2018-06-01          NaN          0   \n",
       "7              2013-03-25             2018-06-01          NaN          0   \n",
       "8              2008-08-04             2010-05-23          NaN          0   \n",
       "9              2014-07-01             2015-10-19          NaN          0   \n",
       "\n",
       "   Age_years  \n",
       "0  52.843258  \n",
       "1  55.373032  \n",
       "2  68.876112  \n",
       "3  35.433265  \n",
       "4  31.865845  \n",
       "5  27.126626  \n",
       "6  56.971937  \n",
       "7  62.168378  \n",
       "8  63.238877  \n",
       "9  60.210815  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(r'PatientAnalyticFile.csv', nrows=10)\n",
    "# Create mortality variable\n",
    "df2['mortality'] = \\\n",
    "    np.where(df2['DateOfDeath'].isnull(), 0,1)\n",
    "\n",
    "# Convert dateofBirth to date\n",
    "df2['DateOfBirth'] = \\\n",
    "    pd.to_datetime(df2['DateOfBirth'])\n",
    "# Calculate age in years as of 2015-01-01\n",
    "df2['Age_years'] = \\\n",
    "    ((pd.to_datetime('2015-01-01') - df2['DateOfBirth']).dt.days/365.25)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age_years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.210622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.954813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.888313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.084923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.346114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.298742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.585132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.644130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.477245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age_years\n",
       "0   0.071199\n",
       "1   0.210622\n",
       "2   0.954813\n",
       "3  -0.888313\n",
       "4  -1.084923\n",
       "5  -1.346114\n",
       "6   0.298742\n",
       "7   0.585132\n",
       "8   0.644130\n",
       "9   0.477245"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## standardized numeric cols\n",
    "X_num=(df2.loc[:,num_cols]-mean_all)/stdev_all\n",
    "X_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mortality ~ Gender+Race+Myocardial_infarction+Congestive_heart_failure+Peripheral_vascular_disease+Stroke+Dementia+Pulmonary+Rheumatic+Peptic_ulcer_disease+LiverMild+Diabetes_without_complications+Diabetes_with_complications+Paralysis+Renal+Cancer+LiverSevere+Metastatic_solid_tumour+HIV+Obesity+Depression+Hypertension+Drugs+Alcohol+mortality'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in cat_cols:\n",
    "    df2[col]=pd.Categorical(df2[col],categories=dict_unique[col])\n",
    "    \n",
    "formula = 'mortality ~ ' + '+'.join(cat_cols)\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y,X_cat =  dmatrices(formula,df2)\n",
    "X_all = np.concatenate([X_cat,X_num],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DesignMatrix with shape (10, 2)\n",
       "  mortality[0]  mortality[1]\n",
       "             1             0\n",
       "             0             1\n",
       "             1             0\n",
       "             0             1\n",
       "             1             0\n",
       "             1             0\n",
       "             1             0\n",
       "             1             0\n",
       "             1             0\n",
       "             1             0\n",
       "  Terms:\n",
       "    'mortality' (columns 0:2)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all=np.concatenate([X_cat,X_num],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,1]\n",
    "classes_potential =  np.array([0,1])\n",
    "classes_potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.13, NNZs: 2, Bias: 0.000000, T: 500, Avg. loss: 0.680285\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.11, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.678611\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.10, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.677224\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.10, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.675749\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.675943\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.674568\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.676897\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.676375\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.09, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.673665\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.674984\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.674292\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.675287\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.674391\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.673779\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.678183\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.675509\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.678191\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.677192\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.673601\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.674815\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.08, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.675655\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.677575\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.675622\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.677387\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.675743\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.674219\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.676619\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 2, Bias: 0.000000, T: 500, Avg. loss: 0.676955\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.678693\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.677234\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.675793\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 2, Bias: 0.000000, T: 500, Avg. loss: 0.674292\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 2, Bias: 0.000000, T: 500, Avg. loss: 0.677789\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 2, Bias: 0.000000, T: 500, Avg. loss: 0.676684\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 2, Bias: 0.000000, T: 500, Avg. loss: 0.676344\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 2, Bias: 0.000000, T: 500, Avg. loss: 0.676743\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 2, Bias: 0.000000, T: 500, Avg. loss: 0.677046\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.678371\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.678963\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.07, NNZs: 3, Bias: 0.000000, T: 500, Avg. loss: 0.674716\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1, average=False, class_weight=None, early_stopping=False,\n",
       "       epsilon=0.1, eta0=0.0, fit_intercept=False, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='log', max_iter=None, n_iter=None,\n",
       "       n_iter_no_change=5, n_jobs=None, penalty='elasticnet', power_t=0.5,\n",
       "       random_state=None, shuffle=True, tol=1e-06, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=True)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_potential =  np.array([0,1])\n",
    "clf =  linear_model.SGDClassifier(fit_intercept=False,\n",
    "                                 loss='log',\n",
    "                                 penalty='elasticnet',\n",
    "                                 warm_start=True,\n",
    "                                 alpha=1,\n",
    "                                 verbose=1,\n",
    "                                 tol=1e-6)\n",
    "## establish generator to yield data\n",
    "df_patient_gen3 = \\\n",
    " pd.read_csv(r'PatientAnalyticFile.csv',\n",
    "             chunksize=500)\n",
    "\n",
    "for n, chunk in enumerate(df_patient_gen3):\n",
    "    chunk['mortality'] = np.where(chunk['DateOfDeath'].isnull(),0,1)\n",
    "    chunk['DateOfBirth'] = pd.to_datetime(chunk['DateOfBirth'])\n",
    "    chunk['Age_years'] = (pd.to_datetime('2019-04-22')-chunk['DateOfBirth']).dt.days/365.25\n",
    "    X_num=(chunk.loc[:,num_cols]-mean_all)/stdev_all\n",
    "    for col in cat_cols:\n",
    "        chunk[col] = pd.Categorical(chunk[col],categories=dict_unique[col])\n",
    "    Y,X_cat = dmatrices(formula,chunk)\n",
    "    X_all = np.concatenate([X_cat,X_num],axis=1)\n",
    "    clf.partial_fit(X_all,Y[:,1],classes=classes_potential)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test the loop!\n",
    "for n,chunk in enumerate(df_patient_gen3):\n",
    "    ## process data first\n",
    "    # Create mortality variable\n",
    "    chunk['mortality'] = \\\n",
    "        np.where(chunk['DateOfDeath'].isnull(),\n",
    "                 0,1)\n",
    "    # Convert dateofBirth to date\n",
    "    chunk['DateOfBirth'] = \\\n",
    "        pd.to_datetime(chunk['DateOfBirth'])\n",
    "    # Calculate age in years as of 2015-01-01\n",
    "    chunk['Age_years'] = \\\n",
    "        ((pd.to_datetime('2019-04-22') - chunk['DateOfBirth']).dt.days/365.25)\n",
    "    # standardized numeric cols\n",
    "    X_num = (chunk.loc[:,num_cols] - mean_all)/stdev_all\n",
    "    ## get dummy coded categoricals\n",
    "    for col in cat_cols:\n",
    "        chunk[col] = pd.Categorical(chunk[col],\n",
    "                                    categories=dict_unique[col])\n",
    "    ## use Patsy to create model matrices\n",
    "    Y,X_cat = dmatrices(formula,\n",
    "                        chunk)\n",
    "    ## join in the continuous X\n",
    "    X_all = np.concatenate([X_cat,X_num],axis=1)\n",
    "    \n",
    "    ## update the fit, one full EPOCH?\n",
    "    clf.partial_fit(X_all,Y[:,1],classes=classes_potential)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
